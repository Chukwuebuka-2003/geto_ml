{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym import spaces\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# Building the Traditional Model\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, RobustScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 151112 entries, 0 to 151111\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   user_id         151112 non-null  int64  \n",
      " 1   signup_time     151112 non-null  object \n",
      " 2   purchase_time   151112 non-null  object \n",
      " 3   purchase_value  151112 non-null  int64  \n",
      " 4   device_id       151112 non-null  object \n",
      " 5   source          151112 non-null  object \n",
      " 6   browser         151112 non-null  object \n",
      " 7   sex             151112 non-null  object \n",
      " 8   age             151112 non-null  int64  \n",
      " 9   ip_address      151112 non-null  float64\n",
      " 10  class           151112 non-null  int64  \n",
      "dtypes: float64(1), int64(4), object(6)\n",
      "memory usage: 12.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Fraud_Data.csv')\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>signup_time</th>\n",
       "      <th>purchase_time</th>\n",
       "      <th>purchase_value</th>\n",
       "      <th>device_id</th>\n",
       "      <th>source</th>\n",
       "      <th>browser</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>ip_address</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22058</td>\n",
       "      <td>2015-02-24 22:55:49</td>\n",
       "      <td>2015-04-18 02:47:11</td>\n",
       "      <td>34</td>\n",
       "      <td>QVPSPJUOCKZAR</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>M</td>\n",
       "      <td>39</td>\n",
       "      <td>7.327584e+08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>333320</td>\n",
       "      <td>2015-06-07 20:39:50</td>\n",
       "      <td>2015-06-08 01:38:54</td>\n",
       "      <td>16</td>\n",
       "      <td>EOGFQPIZPYXFZ</td>\n",
       "      <td>Ads</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>F</td>\n",
       "      <td>53</td>\n",
       "      <td>3.503114e+08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1359</td>\n",
       "      <td>2015-01-01 18:52:44</td>\n",
       "      <td>2015-01-01 18:52:45</td>\n",
       "      <td>15</td>\n",
       "      <td>YSSKYOSJHPPLJ</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Opera</td>\n",
       "      <td>M</td>\n",
       "      <td>53</td>\n",
       "      <td>2.621474e+09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150084</td>\n",
       "      <td>2015-04-28 21:13:25</td>\n",
       "      <td>2015-05-04 13:54:50</td>\n",
       "      <td>44</td>\n",
       "      <td>ATGTXKYKUDUQN</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Safari</td>\n",
       "      <td>M</td>\n",
       "      <td>41</td>\n",
       "      <td>3.840542e+09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>221365</td>\n",
       "      <td>2015-07-21 07:09:52</td>\n",
       "      <td>2015-09-09 18:40:53</td>\n",
       "      <td>39</td>\n",
       "      <td>NAUITBZFJKHWW</td>\n",
       "      <td>Ads</td>\n",
       "      <td>Safari</td>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>4.155831e+08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id          signup_time        purchase_time  purchase_value  \\\n",
       "0    22058  2015-02-24 22:55:49  2015-04-18 02:47:11              34   \n",
       "1   333320  2015-06-07 20:39:50  2015-06-08 01:38:54              16   \n",
       "2     1359  2015-01-01 18:52:44  2015-01-01 18:52:45              15   \n",
       "3   150084  2015-04-28 21:13:25  2015-05-04 13:54:50              44   \n",
       "4   221365  2015-07-21 07:09:52  2015-09-09 18:40:53              39   \n",
       "\n",
       "       device_id source browser sex  age    ip_address  class  \n",
       "0  QVPSPJUOCKZAR    SEO  Chrome   M   39  7.327584e+08      0  \n",
       "1  EOGFQPIZPYXFZ    Ads  Chrome   F   53  3.503114e+08      0  \n",
       "2  YSSKYOSJHPPLJ    SEO   Opera   M   53  2.621474e+09      1  \n",
       "3  ATGTXKYKUDUQN    SEO  Safari   M   41  3.840542e+09      0  \n",
       "4  NAUITBZFJKHWW    Ads  Safari   M   45  4.155831e+08      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering\n",
    "\n",
    "df['signup_date'] = pd.to_datetime(df['signup_time'])\n",
    "df['purchase_time'] = pd.to_datetime(df['purchase_time'])\n",
    "df['time_Since_signup'] = (df['purchase_time'] - df['signup_date']).dt.total_seconds()\n",
    "df['time_of_day'] =df['purchase_time'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>signup_time</th>\n",
       "      <th>purchase_time</th>\n",
       "      <th>purchase_value</th>\n",
       "      <th>device_id</th>\n",
       "      <th>source</th>\n",
       "      <th>browser</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>ip_address</th>\n",
       "      <th>class</th>\n",
       "      <th>signup_date</th>\n",
       "      <th>time_Since_signup</th>\n",
       "      <th>time_of_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22058</td>\n",
       "      <td>2015-02-24 22:55:49</td>\n",
       "      <td>2015-04-18 02:47:11</td>\n",
       "      <td>34</td>\n",
       "      <td>QVPSPJUOCKZAR</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>M</td>\n",
       "      <td>39</td>\n",
       "      <td>7.327584e+08</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-02-24 22:55:49</td>\n",
       "      <td>4506682.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>333320</td>\n",
       "      <td>2015-06-07 20:39:50</td>\n",
       "      <td>2015-06-08 01:38:54</td>\n",
       "      <td>16</td>\n",
       "      <td>EOGFQPIZPYXFZ</td>\n",
       "      <td>Ads</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>F</td>\n",
       "      <td>53</td>\n",
       "      <td>3.503114e+08</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-06-07 20:39:50</td>\n",
       "      <td>17944.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1359</td>\n",
       "      <td>2015-01-01 18:52:44</td>\n",
       "      <td>2015-01-01 18:52:45</td>\n",
       "      <td>15</td>\n",
       "      <td>YSSKYOSJHPPLJ</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Opera</td>\n",
       "      <td>M</td>\n",
       "      <td>53</td>\n",
       "      <td>2.621474e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-01 18:52:44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150084</td>\n",
       "      <td>2015-04-28 21:13:25</td>\n",
       "      <td>2015-05-04 13:54:50</td>\n",
       "      <td>44</td>\n",
       "      <td>ATGTXKYKUDUQN</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Safari</td>\n",
       "      <td>M</td>\n",
       "      <td>41</td>\n",
       "      <td>3.840542e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-04-28 21:13:25</td>\n",
       "      <td>492085.0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>221365</td>\n",
       "      <td>2015-07-21 07:09:52</td>\n",
       "      <td>2015-09-09 18:40:53</td>\n",
       "      <td>39</td>\n",
       "      <td>NAUITBZFJKHWW</td>\n",
       "      <td>Ads</td>\n",
       "      <td>Safari</td>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>4.155831e+08</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-07-21 07:09:52</td>\n",
       "      <td>4361461.0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id          signup_time       purchase_time  purchase_value  \\\n",
       "0    22058  2015-02-24 22:55:49 2015-04-18 02:47:11              34   \n",
       "1   333320  2015-06-07 20:39:50 2015-06-08 01:38:54              16   \n",
       "2     1359  2015-01-01 18:52:44 2015-01-01 18:52:45              15   \n",
       "3   150084  2015-04-28 21:13:25 2015-05-04 13:54:50              44   \n",
       "4   221365  2015-07-21 07:09:52 2015-09-09 18:40:53              39   \n",
       "\n",
       "       device_id source browser sex  age    ip_address  class  \\\n",
       "0  QVPSPJUOCKZAR    SEO  Chrome   M   39  7.327584e+08      0   \n",
       "1  EOGFQPIZPYXFZ    Ads  Chrome   F   53  3.503114e+08      0   \n",
       "2  YSSKYOSJHPPLJ    SEO   Opera   M   53  2.621474e+09      1   \n",
       "3  ATGTXKYKUDUQN    SEO  Safari   M   41  3.840542e+09      0   \n",
       "4  NAUITBZFJKHWW    Ads  Safari   M   45  4.155831e+08      0   \n",
       "\n",
       "          signup_date  time_Since_signup  time_of_day  \n",
       "0 2015-02-24 22:55:49          4506682.0            2  \n",
       "1 2015-06-07 20:39:50            17944.0            1  \n",
       "2 2015-01-01 18:52:44                1.0           18  \n",
       "3 2015-04-28 21:13:25           492085.0           13  \n",
       "4 2015-07-21 07:09:52          4361461.0           18  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SEO', 'Ads', 'Direct'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['source'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select features for state representation\n",
    "\n",
    "features = ['source', 'time_Since_signup', 'time_of_day', 'age', 'sex', 'device_id']\n",
    "\n",
    "X = df[features]\n",
    "y = df['class']\n",
    "\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "scaler = RobustScaler()\n",
    "\n",
    "cat_cols = ['sex', 'device_id', 'source']\n",
    "num_col = ['age', 'time_Since_signup', 'time_of_day']\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', scaler, num_col),\n",
    "        ('cat', ohe, cat_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_preprocessed = preprocessor.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_preprocessed, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 155. GiB for an array with shape (151112, 137964) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Address class imbalance with SMOTE (convert sparse to dense only during resampling)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m smote \u001b[38;5;241m=\u001b[39m SMOTE(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m X_resampled, y_resampled \u001b[38;5;241m=\u001b[39m smote\u001b[38;5;241m.\u001b[39mfit_resample(X_preprocessed\u001b[38;5;241m.\u001b[39mtoarray(), y)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Split the data into training and testing sets\u001b[39;00m\n\u001b[1;32m     24\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X_resampled, y_resampled, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/scipy/sparse/_compressed.py:1050\u001b[0m, in \u001b[0;36m_cs_matrix.toarray\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m order \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1049\u001b[0m     order \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_swap(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcf\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m-> 1050\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_toarray_args(order, out)\n\u001b[1;32m   1051\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (out\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mc_contiguous \u001b[38;5;129;01mor\u001b[39;00m out\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mf_contiguous):\n\u001b[1;32m   1052\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOutput array must be C or F contiguous\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/scipy/sparse/_base.py:1267\u001b[0m, in \u001b[0;36m_spbase._process_toarray_args\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m   1265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[1;32m   1266\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1267\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39morder)\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 155. GiB for an array with shape (151112, 137964) and data type float64"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "# Select numerical features to discretize\n",
    "numerical_features = ['age', 'time_Since_signup', 'time_of_day']\n",
    "categorical_features = list(set(X.columns) - set(numerical_features))\n",
    "\n",
    "# Apply OneHotEncoder to categorical features and KBinsDiscretizer to numerical features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='uniform'), numerical_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=True), categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit and transform the features\n",
    "X_preprocessed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Address class imbalance with SMOTE (convert sparse to dense only during resampling)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_preprocessed.toarray(), y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert the training and testing data into tuples for Q-learning\n",
    "X_train_tuples = [tuple(state) for state in X_train]\n",
    "X_test_tuples = [tuple(state) for state in X_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m n_bins \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m      4\u001b[0m kbins \u001b[38;5;241m=\u001b[39m KBinsDiscretizer(n_bins\u001b[38;5;241m=\u001b[39mn_bins, encode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mordinal\u001b[39m\u001b[38;5;124m'\u001b[39m, strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muniform\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m X_train_discrete \u001b[38;5;241m=\u001b[39m kbins\u001b[38;5;241m.\u001b[39mfit_transform(X_train)\n\u001b[1;32m      6\u001b[0m X_test_discrete \u001b[38;5;241m=\u001b[39m kbins\u001b[38;5;241m.\u001b[39mtransform(X_test)\n\u001b[1;32m      8\u001b[0m X_train_tuples \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mtuple\u001b[39m(state) \u001b[38;5;28;01mfor\u001b[39;00m state \u001b[38;5;129;01min\u001b[39;00m X_train_discrete]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:878\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[38;5;66;03m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;66;03m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    877\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m    881\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_discretization.py:204\u001b[0m, in \u001b[0;36mKBinsDiscretizer.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;124;03mFit the estimator.\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;124;03m    Returns the instance itself.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m--> 204\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01min\u001b[39;00m (np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32):\n\u001b[1;32m    207\u001b[0m     output_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    563\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 565\u001b[0m     X \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[1;32m    566\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:845\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sp\u001b[38;5;241m.\u001b[39missparse(array):\n\u001b[1;32m    844\u001b[0m     _ensure_no_complex_data(array)\n\u001b[0;32m--> 845\u001b[0m     array \u001b[38;5;241m=\u001b[39m _ensure_sparse_format(\n\u001b[1;32m    846\u001b[0m         array,\n\u001b[1;32m    847\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m    848\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    849\u001b[0m         copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[1;32m    850\u001b[0m         force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[1;32m    851\u001b[0m         accept_large_sparse\u001b[38;5;241m=\u001b[39maccept_large_sparse,\n\u001b[1;32m    852\u001b[0m         estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[1;32m    853\u001b[0m         input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[1;32m    854\u001b[0m     )\n\u001b[1;32m    855\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;66;03m# If np.array(..) gives ComplexWarning, then we convert the warning\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;66;03m# to an error. This is needed because specifying a non complex\u001b[39;00m\n\u001b[1;32m    858\u001b[0m     \u001b[38;5;66;03m# dtype to the function converts complex to real dtype,\u001b[39;00m\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# thereby passing the test made in the lines following the scope\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# of warnings context manager.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:522\u001b[0m, in \u001b[0;36m_ensure_sparse_format\u001b[0;34m(spmatrix, accept_sparse, dtype, copy, force_all_finite, accept_large_sparse, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    519\u001b[0m _check_large_sparse(spmatrix, accept_large_sparse)\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m accept_sparse \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m--> 522\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    523\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA sparse matrix was passed, but dense \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    524\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata is required. Use X.toarray() to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    525\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconvert to a dense numpy array.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    526\u001b[0m     )\n\u001b[1;32m    527\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(accept_sparse, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m    528\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(accept_sparse) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mTypeError\u001b[0m: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array."
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "n_bins = 10\n",
    "kbins = KBinsDiscretizer(n_bins=n_bins, encode='ordinal', strategy='uniform')\n",
    "X_train_discrete = kbins.fit_transform(X_train)\n",
    "X_test_discrete = kbins.transform(X_test)\n",
    "\n",
    "X_train_tuples = [tuple(state) for state in X_train_discrete]\n",
    "X_test_tuples = [tuple(state) for state in X_test_discrete]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sparse array length is ambiguous; use getnnz() or shape[0]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 21\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epsiode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m---> 21\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X_train)):\n\u001b[1;32m     22\u001b[0m         state \u001b[38;5;241m=\u001b[39m X_train[i]\n\u001b[1;32m     23\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m random\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m<\u001b[39m epsilon:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/scipy/sparse/_base.py:340\u001b[0m, in \u001b[0;36m_spbase.__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__len__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 340\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse array length is ambiguous; use getnnz()\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    341\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or shape[0]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: sparse array length is ambiguous; use getnnz() or shape[0]"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "state_size = X_train.shape[1]\n",
    "\n",
    "action_size = 2\n",
    "\n",
    "Q = np.zeros((state_size * 10, action_size))\n",
    "\n",
    "alpha = 0.1\n",
    "gamma = 0.9\n",
    "epsilon = 0.1\n",
    "n_actions = 3\n",
    "\n",
    "q_table = defaultdict(lambda: np.zeros(n_actions))\n",
    "n_episodes = 10\n",
    "\n",
    "for epsiode in range(n_episodes):\n",
    "    state = random.\n",
    "\n",
    "def reward(prediction, actual):\n",
    "    if prediction == actual:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "\n",
    "for epsiode in range(10):\n",
    "    for i in range(len(X_train)):\n",
    "        state = X_train[i]\n",
    "        if random.uniform(0,1) < epsilon:\n",
    "            action = random.randint(0, action_size - 1)\n",
    "        else:\n",
    "            action = np.argmax(Q[np.argmax(state)])\n",
    "\n",
    "        prediction = action\n",
    "        reward = reward(prediction, y_train[i])\n",
    "\n",
    "        best_next_action = np.argmax(Q[np.argmax(state)])\n",
    "        Q[np.argmax(state), action] += alpha * (reward + gamma * Q[np.argmax(state), best_next_action] - Q[np.argmax(state), action])\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    state = X_test[i]\n",
    "    action = np.argmax(Q[np.argmax(state)])\n",
    "    predictions.append(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
