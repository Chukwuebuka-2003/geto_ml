{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 151112 entries, 0 to 151111\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   user_id         151112 non-null  int64  \n",
      " 1   signup_time     151112 non-null  object \n",
      " 2   purchase_time   151112 non-null  object \n",
      " 3   purchase_value  151112 non-null  int64  \n",
      " 4   device_id       151112 non-null  object \n",
      " 5   source          151112 non-null  object \n",
      " 6   browser         151112 non-null  object \n",
      " 7   sex             151112 non-null  object \n",
      " 8   age             151112 non-null  int64  \n",
      " 9   ip_address      151112 non-null  float64\n",
      " 10  class           151112 non-null  int64  \n",
      "dtypes: float64(1), int64(4), object(6)\n",
      "memory usage: 12.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Fraud_Data.csv')\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>signup_time</th>\n",
       "      <th>purchase_time</th>\n",
       "      <th>purchase_value</th>\n",
       "      <th>device_id</th>\n",
       "      <th>source</th>\n",
       "      <th>browser</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>ip_address</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22058</td>\n",
       "      <td>2015-02-24 22:55:49</td>\n",
       "      <td>2015-04-18 02:47:11</td>\n",
       "      <td>34</td>\n",
       "      <td>QVPSPJUOCKZAR</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>M</td>\n",
       "      <td>39</td>\n",
       "      <td>7.327584e+08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>333320</td>\n",
       "      <td>2015-06-07 20:39:50</td>\n",
       "      <td>2015-06-08 01:38:54</td>\n",
       "      <td>16</td>\n",
       "      <td>EOGFQPIZPYXFZ</td>\n",
       "      <td>Ads</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>F</td>\n",
       "      <td>53</td>\n",
       "      <td>3.503114e+08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1359</td>\n",
       "      <td>2015-01-01 18:52:44</td>\n",
       "      <td>2015-01-01 18:52:45</td>\n",
       "      <td>15</td>\n",
       "      <td>YSSKYOSJHPPLJ</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Opera</td>\n",
       "      <td>M</td>\n",
       "      <td>53</td>\n",
       "      <td>2.621474e+09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150084</td>\n",
       "      <td>2015-04-28 21:13:25</td>\n",
       "      <td>2015-05-04 13:54:50</td>\n",
       "      <td>44</td>\n",
       "      <td>ATGTXKYKUDUQN</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Safari</td>\n",
       "      <td>M</td>\n",
       "      <td>41</td>\n",
       "      <td>3.840542e+09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>221365</td>\n",
       "      <td>2015-07-21 07:09:52</td>\n",
       "      <td>2015-09-09 18:40:53</td>\n",
       "      <td>39</td>\n",
       "      <td>NAUITBZFJKHWW</td>\n",
       "      <td>Ads</td>\n",
       "      <td>Safari</td>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>4.155831e+08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id          signup_time        purchase_time  purchase_value  \\\n",
       "0    22058  2015-02-24 22:55:49  2015-04-18 02:47:11              34   \n",
       "1   333320  2015-06-07 20:39:50  2015-06-08 01:38:54              16   \n",
       "2     1359  2015-01-01 18:52:44  2015-01-01 18:52:45              15   \n",
       "3   150084  2015-04-28 21:13:25  2015-05-04 13:54:50              44   \n",
       "4   221365  2015-07-21 07:09:52  2015-09-09 18:40:53              39   \n",
       "\n",
       "       device_id source browser sex  age    ip_address  class  \n",
       "0  QVPSPJUOCKZAR    SEO  Chrome   M   39  7.327584e+08      0  \n",
       "1  EOGFQPIZPYXFZ    Ads  Chrome   F   53  3.503114e+08      0  \n",
       "2  YSSKYOSJHPPLJ    SEO   Opera   M   53  2.621474e+09      1  \n",
       "3  ATGTXKYKUDUQN    SEO  Safari   M   41  3.840542e+09      0  \n",
       "4  NAUITBZFJKHWW    Ads  Safari   M   45  4.155831e+08      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id           0\n",
       "signup_time       0\n",
       "purchase_time     0\n",
       "purchase_value    0\n",
       "device_id         0\n",
       "source            0\n",
       "browser           0\n",
       "sex               0\n",
       "age               0\n",
       "ip_address        0\n",
       "class             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset has a total number of 14151 fraud labels and a total number of 136961 non-fraud labels \n"
     ]
    }
   ],
   "source": [
    "fraud_label = df.loc[df['class'] == 1]\n",
    "non_fraud_label =  df.loc[df['class'] == 0]\n",
    "\n",
    "print(f\"This dataset has a total number of {len(fraud_label)} fraud labels and a total number of {len(non_fraud_label)} non-fraud labels \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation: In this scenario, there seems to be a huge number of class imbalance, because the fraud labels and non fraud labels difference is huge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the signup_time and the purchase_time columns to datetime\n",
    "import datetime\n",
    "\n",
    "df['signup_time'] = pd.to_datetime(df['signup_time'])\n",
    "\n",
    "df['purchase_time'] = pd.to_datetime(df['purchase_time'])\n",
    "\n",
    "df['signup_hour'] = df['signup_time'].dt.hour\n",
    "\n",
    "df['purchase_hour'] = df['purchase_time'].dt.hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Important Observation When Building Trad ML For Fraud Prediction\n",
    "\n",
    "In fraud prediction models, F1 score is generally more important than Accuracy for both model evaluation and comparison. \n",
    "\n",
    "This is because fraud detection often involves imbalanced datasets where the cost of false negatives (FN) can be significant. \n",
    "\n",
    "F1 SCore balances precision and recall, this makes it effective in a scenario where bpth false positives and false negatives are critical.\n",
    "\n",
    "Relying on Accuracy can be misleading, especially if the model predicts the majority class well but fails to identify fraud effectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the Traditional Model\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, RobustScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'signup_time', 'purchase_time', 'purchase_value',\n",
       "       'device_id', 'source', 'browser', 'sex', 'age', 'ip_address', 'class',\n",
       "       'signup_hour', 'purchase_hour'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['class', 'signup_time', 'purchase_time', 'user_id', 'device_id', 'ip_address'], axis=1)\n",
    "y = df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['source', 'browser', 'sex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_col = ['purchase_value', 'age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;, RobustScaler(),\n",
       "                                 [&#x27;purchase_value&#x27;, &#x27;age&#x27;]),\n",
       "                                (&#x27;cat&#x27;, OneHotEncoder(),\n",
       "                                 [&#x27;source&#x27;, &#x27;browser&#x27;, &#x27;sex&#x27;])])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;, RobustScaler(),\n",
       "                                 [&#x27;purchase_value&#x27;, &#x27;age&#x27;]),\n",
       "                                (&#x27;cat&#x27;, OneHotEncoder(),\n",
       "                                 [&#x27;source&#x27;, &#x27;browser&#x27;, &#x27;sex&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[&#x27;purchase_value&#x27;, &#x27;age&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RobustScaler</label><div class=\"sk-toggleable__content\"><pre>RobustScaler()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>[&#x27;source&#x27;, &#x27;browser&#x27;, &#x27;sex&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "ColumnTransformer(transformers=[('num', RobustScaler(),\n",
       "                                 ['purchase_value', 'age']),\n",
       "                                ('cat', OneHotEncoder(),\n",
       "                                 ['source', 'browser', 'sex'])])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe = OneHotEncoder()\n",
    "scaler = RobustScaler()\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', scaler, num_col),\n",
    "        ('cat', ohe, cat_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the classifiers i intend to work with\n",
    "# hyperparameter optimisation isn't done yet\n",
    "models  = {\n",
    "    'RandomForest': RandomForestClassifier(random_state=42),\n",
    "    'LogisticRegression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'XGBoost Classifier': XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RandomForest\n",
      "Accuracy: 0.9206\n",
      "The Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96     27373\n",
      "           1       0.60      0.48      0.53      2850\n",
      "\n",
      "    accuracy                           0.92     30223\n",
      "   macro avg       0.77      0.72      0.74     30223\n",
      "weighted avg       0.91      0.92      0.92     30223\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Model: LogisticRegression\n",
      "Accuracy: 0.9057\n",
      "The Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     27373\n",
      "           1       0.00      0.00      0.00      2850\n",
      "\n",
      "    accuracy                           0.91     30223\n",
      "   macro avg       0.45      0.50      0.48     30223\n",
      "weighted avg       0.82      0.91      0.86     30223\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Model: XGBoost Classifier\n",
      "Accuracy: 0.9096\n",
      "The Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     27373\n",
      "           1       0.79      0.06      0.11      2850\n",
      "\n",
      "    accuracy                           0.91     30223\n",
      "   macro avg       0.85      0.53      0.53     30223\n",
      "weighted avg       0.90      0.91      0.87     30223\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train and evaluate each model\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "for model_name, model in  models.items():\n",
    "    pipeline = Pipeline(\n",
    "        steps=[('preprocessor', preprocessor),\n",
    "               ('classifier', model)]\n",
    "    )\n",
    "\n",
    "    # fit the model\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # make a prediction on the test set\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    #evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "\n",
    "    # print the results \n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(\"The Classification Report:\")\n",
    "    print(report)\n",
    "    print(\"\\n\" + \"-\"*60 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RandomForest\n",
      "Accuracy: 0.9051\n",
      "The Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95     27393\n",
      "           1       0.49      0.56      0.52      2830\n",
      "\n",
      "    accuracy                           0.91     30223\n",
      "   macro avg       0.72      0.75      0.74     30223\n",
      "weighted avg       0.91      0.91      0.91     30223\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Model: LogisticRegression\n",
      "Accuracy: 0.5344\n",
      "The Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.54      0.68     27393\n",
      "           1       0.10      0.50      0.17      2830\n",
      "\n",
      "    accuracy                           0.53     30223\n",
      "   macro avg       0.51      0.52      0.42     30223\n",
      "weighted avg       0.84      0.53      0.63     30223\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Model: XGBoost Classifier\n",
      "Accuracy: 0.7986\n",
      "The Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.83      0.88     27393\n",
      "           1       0.23      0.51      0.32      2830\n",
      "\n",
      "    accuracy                           0.80     30223\n",
      "   macro avg       0.59      0.67      0.60     30223\n",
      "weighted avg       0.88      0.80      0.83     30223\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# now i will apply SMOTE because I need to fix the issue of the class imbalance\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "for model_name, model in  models.items():\n",
    "    pipeline = Pipeline(\n",
    "        steps=[('preprocessor', preprocessor),\n",
    "               ('smote', SMOTE(random_state=42)),\n",
    "               ('classifier', model)]\n",
    "    )\n",
    "\n",
    "    # fit the model\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # make a prediction on the test set\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    #evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "\n",
    "    # print the results \n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(\"The Classification Report:\")\n",
    "    print(report)\n",
    "    print(\"\\n\" + \"-\"*60 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RandomForest\n",
      "The Models Best Parameters: {'classifier__n_estimators': 200, 'classifier__min_samples_split': 2, 'classifier__min_samples_leaf': 2, 'classifier__max_depth': None}\n",
      "Accuracy score: 0.9075\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95     27393\n",
      "           1       0.51      0.56      0.53      2830\n",
      "\n",
      "    accuracy                           0.91     30223\n",
      "   macro avg       0.73      0.75      0.74     30223\n",
      "weighted avg       0.91      0.91      0.91     30223\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Model: LogisticRegression\n",
      "The Models Best Parameters: {'classifier__solver': 'liblinear', 'classifier__penalty': 'l1', 'classifier__C': 0.0006951927961775605}\n",
      "Accuracy score: 0.7460\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.80      0.85     27393\n",
      "           1       0.10      0.22      0.14      2830\n",
      "\n",
      "    accuracy                           0.75     30223\n",
      "   macro avg       0.50      0.51      0.49     30223\n",
      "weighted avg       0.83      0.75      0.78     30223\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stocks/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [00:10:18] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/stocks/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [00:10:18] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/stocks/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [00:10:18] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/stocks/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [00:10:18] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/stocks/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [00:10:27] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/stocks/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [00:10:27] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/stocks/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [00:10:28] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/stocks/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [00:10:33] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/stocks/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [00:10:35] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/stocks/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [00:10:36] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/stocks/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [00:10:39] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/stocks/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [00:10:42] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/stocks/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [00:10:45] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/stocks/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [00:10:46] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/stocks/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [00:10:47] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/stocks/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [00:10:47] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/stocks/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [00:10:54] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/stocks/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [00:11:01] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/stocks/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [00:11:01] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/stocks/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [00:11:02] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/stocks/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [00:11:02] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/stocks/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [00:11:05] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/stocks/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [00:11:10] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/stocks/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [00:11:10] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/stocks/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [00:11:10] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/stocks/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [00:11:19] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/stocks/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [00:11:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/stocks/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [00:11:23] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/stocks/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [00:11:25] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/stocks/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [00:11:33] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: XGBoost Classifier\n",
      "The Models Best Parameters: {'classifier__subsample': 0.7, 'classifier__n_estimators': 50, 'classifier__max_depth': 10, 'classifier__learning_rate': 0.3}\n",
      "Accuracy score: 0.8628\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.89      0.92     27393\n",
      "           1       0.35      0.56      0.43      2830\n",
      "\n",
      "    accuracy                           0.86     30223\n",
      "   macro avg       0.65      0.73      0.68     30223\n",
      "weighted avg       0.90      0.86      0.88     30223\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter optimization\n",
    "\n",
    "models = {\n",
    "    'RandomForest': {\n",
    "        'classifier': RandomForestClassifier(random_state=42),\n",
    "        'params': {\n",
    "            'classifier__n_estimators': [50, 100, 200],\n",
    "            'classifier__max_depth': [None, 10, 20, 30],\n",
    "            'classifier__min_samples_split': [2,5,10],\n",
    "            'classifier__min_samples_leaf': [1,2,4]\n",
    "        }\n",
    "    },\n",
    "\n",
    "    'LogisticRegression' : {\n",
    "        'classifier': LogisticRegression(max_iter=1000, random_state=42),\n",
    "        'params': {\n",
    "            'classifier__C': np.logspace(-4, 4, 20),\n",
    "            'classifier__penalty': ['l1', 'l2'],\n",
    "            'classifier__solver': ['liblinear']\n",
    "        }\n",
    "    },\n",
    "    'XGBoost Classifier' : {\n",
    "        'classifier' : XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
    "        'params' : {\n",
    "            'classifier__n_estimators': [50, 100, 200],\n",
    "            'classifier__max_depth': [3, 6, 10],\n",
    "            'classifier__learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "            'classifier__subsample': [0.7, 0.8, 0.9, 1.0]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "for model_name, model_dict in models.items():\n",
    "    pipeline = Pipeline(steps= [\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('classifier', model_dict['classifier'])\n",
    "    ])\n",
    "\n",
    "    random_cv = RandomizedSearchCV(\n",
    "        pipeline,\n",
    "        param_distributions= model_dict['params'],\n",
    "        n_iter= 10,\n",
    "        scoring= 'accuracy',\n",
    "        cv=3,\n",
    "        random_state=42,\n",
    "        n_jobs= -1\n",
    "    )\n",
    "\n",
    "    # fitting the model with RandomizedSearchCV\n",
    "    random_cv.fit(X_train, y_train)\n",
    "\n",
    "    # predict on the test set\n",
    "    y_pred = random_cv.best_estimator_.predict(X_test)\n",
    "\n",
    "    #model evaluation\n",
    "    accuracy= accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"The Models Best Parameters: {random_cv.best_params_}\")\n",
    "    print(f\"Accuracy score: {accuracy:.4f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(report)\n",
    "    print(\"\\n\" + \"-\"*60 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparisons After The Hyperparameter Tuning\n",
    "\n",
    "Random Forest Model:\n",
    "\n",
    "- F1 score for class 0 (non-fraud): 0.95\n",
    "- F1 score for class 1 (fraud): 0.53\n",
    "- Weighted average F1 score: 0.91\n",
    "\n",
    "\n",
    "Logistic Regression Model:\n",
    "\n",
    "- F1 score for class 0 (non-fraud): 0.85\n",
    "- F1 score for class 1 (fraud): 0.14\n",
    "- Weighted average F1 score: 0.78\n",
    "\n",
    "\n",
    "XGBoost Classifier:\n",
    "\n",
    "- F1 score for class 0 (non-fraud): 0.92\n",
    "- F1 score for class 1 (fraud): 0.43\n",
    "- Weighted average F1 score: 0.88\n",
    "\n",
    "\n",
    "Overall performance:\n",
    "\n",
    "Random Forest still performs the best, followed closely by XGBoost, and then Logistic Regression.\n",
    "\n",
    "The weighted average F1 scores are: \n",
    "\n",
    "- Random Forest (0.91) \n",
    "- XGBoost (0.88) \n",
    "- Logistic Regression (0.78).\n",
    "\n",
    "\n",
    "Non-fraud detection (class 0):\n",
    "\n",
    "Random Forest (0.95) slightly outperforms XGBoost (0.92) and Logistic Regression (0.85).\n",
    "\n",
    "All models perform well in identifying non-fraudulent cases.\n",
    "\n",
    "\n",
    "Fraud detection (class 1):\n",
    "\n",
    "Random Forest (0.53) performs best, followed by XGBoost (0.43), with Logistic Regression (0.14) significantly behind.\n",
    "\n",
    "This is crucial for fraud detection, as identifying the minority class (fraudulent cases) is typically the primary goal.\n",
    "\n",
    "\n",
    "Model ranking based on F1 scores:\n",
    "\n",
    "- Random Forest\n",
    "- XGBoost\n",
    "- Logistic Regression\n",
    "\n",
    "For this fraud prediction task, both ensemble methods (Random Forest and XGBoost) did display superior performance compared to the simpler Logistic Regression model, highlighting the effectiveness of more complex, tree-based algorithms for this particular research topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
